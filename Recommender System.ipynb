{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38df323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /root/anaconda3/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /root/anaconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/anaconda3/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /root/anaconda3/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /root/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--2023-07-20 07:54:59--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip.1’\n",
      "\n",
      "ml-latest-small.zip 100%[===================>] 955.28K   941KB/s    in 1.0s    \n",
      "\n",
      "2023-07-20 07:55:01 (941 KB/s) - ‘ml-latest-small.zip.1’ saved [978202/978202]\n",
      "\n",
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Download MovieLens data\n",
    "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "!unzip ml-latest-small.zip\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "movies_df = pd.read_csv('ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27becafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize encoders\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "# Fit encoders and transform data\n",
    "ratings_df['userId'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['movieId'] = movie_encoder.fit_transform(ratings_df['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3713dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        userId  movieId  rating   timestamp\n",
       " 0            0        0     4.0   964982703\n",
       " 1            0        2     4.0   964981247\n",
       " 2            0        5     4.0   964982224\n",
       " 3            0       43     5.0   964983815\n",
       " 4            0       46     5.0   964982931\n",
       " ...        ...      ...     ...         ...\n",
       " 100831     609     9416     4.0  1493848402\n",
       " 100832     609     9443     5.0  1493850091\n",
       " 100833     609     9444     5.0  1494273047\n",
       " 100834     609     9445     5.0  1493846352\n",
       " 100835     609     9485     3.0  1493846415\n",
       " \n",
       " [100836 rows x 4 columns],\n",
       " 609,\n",
       " 9723)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df,\\\n",
    "ratings_df['userId'].max(),\\\n",
    "ratings_df['movieId'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d448403",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m      4\u001b[0m user_num, movie_num \u001b[38;5;241m=\u001b[39m ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m ratings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m user_num\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "user_num, movie_num = ratings_df['userId'].max()+1, ratings_df['movieId'].max()+1\n",
    "ratings_df['movieId'] += user_num\n",
    "\n",
    "# Build edge index (source and target nodes for each edge)\n",
    "edge_index = torch.tensor(ratings_df[['userId', 'movieId']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create node features (here just one-hot encoding)\n",
    "x = torch.eye( user_num+movie_num, dtype=torch.float)\n",
    "\n",
    "# Create edge features (ratings)\n",
    "edge_attr = torch.tensor(ratings_df[['rating']].values, dtype=torch.float)\n",
    "\n",
    "# Create graph data\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47b4df87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[10334, 10334], edge_index=[2, 100836], edge_attr=[100836, 1]),\n",
       " tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]),\n",
       " torch.Size([10334, 10334]),\n",
       " tensor([[    0,     0,     0,  ...,   609,   609,   609],\n",
       "         [  610,   612,   615,  ..., 10054, 10055, 10095]]),\n",
       " torch.Size([2, 100836]),\n",
       " tensor([[4.],\n",
       "         [4.],\n",
       "         [4.],\n",
       "         ...,\n",
       "         [5.],\n",
       "         [5.],\n",
       "         [3.]]),\n",
       " torch.Size([100836, 1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,\\\n",
    "x, x.shape, \\\n",
    "edge_index, edge_index.shape,\\\n",
    "edge_attr, edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f1da69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class RecommenderSystem(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecommenderSystem, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "        self.embed = torch.nn.Linear(64, 32)  # output embedding of size 32\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.embed(x)  # output a dense embedding for each node\n",
    "\n",
    "        return x  # now x has shape [num_nodes, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad0b1558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training MSE: 12.040426254272461\n",
      "Epoch: 100, Training MSE: 1.3198031187057495\n",
      "Epoch: 200, Training MSE: 0.7992702126502991\n",
      "Epoch: 300, Training MSE: 0.7833868861198425\n",
      "Epoch: 400, Training MSE: 0.7688291668891907\n",
      "Epoch: 500, Training MSE: 0.7556441426277161\n",
      "Epoch: 600, Training MSE: 0.7491211295127869\n",
      "Epoch: 700, Training MSE: 0.743732213973999\n",
      "Epoch: 800, Training MSE: 0.7376899123191833\n",
      "Epoch: 900, Training MSE: 0.7319514751434326\n",
      "Epoch: 1000, Training MSE: 0.7270088791847229\n",
      "Epoch: 1100, Training MSE: 0.7241324186325073\n",
      "Epoch: 1200, Training MSE: 0.7227562665939331\n",
      "Epoch: 1300, Training MSE: 0.7215970158576965\n",
      "Epoch: 1400, Training MSE: 0.7214637398719788\n",
      "Epoch: 1500, Training MSE: 0.7215844988822937\n",
      "Epoch: 1600, Training MSE: 0.7200896739959717\n",
      "Epoch: 1700, Training MSE: 0.7199994325637817\n",
      "Epoch: 1800, Training MSE: 0.7201172113418579\n",
      "Epoch: 1900, Training MSE: 0.7192979454994202\n",
      "Epoch: 2000, Training MSE: 0.7201182842254639\n",
      "Epoch: 2100, Training MSE: 0.7198350429534912\n",
      "Epoch: 2200, Training MSE: 0.7206962704658508\n",
      "Epoch: 2300, Training MSE: 0.7188915610313416\n",
      "Epoch: 2400, Training MSE: 0.7197818756103516\n",
      "Epoch: 2500, Training MSE: 0.7187849283218384\n",
      "Epoch: 2600, Training MSE: 0.7226526737213135\n",
      "Epoch: 2700, Training MSE: 0.7187111377716064\n",
      "Epoch: 2800, Training MSE: 0.7245667576789856\n",
      "Epoch: 2900, Training MSE: 0.7191646099090576\n",
      "Epoch: 3000, Training MSE: 0.7188206911087036\n",
      "Epoch: 3100, Training MSE: 0.7189663648605347\n",
      "Epoch: 3200, Training MSE: 0.7191731929779053\n",
      "Epoch: 3300, Training MSE: 0.7188997864723206\n",
      "Epoch: 3400, Training MSE: 0.7188777923583984\n",
      "Epoch: 3500, Training MSE: 0.7187326550483704\n",
      "Epoch: 3600, Training MSE: 0.7185757756233215\n",
      "Epoch: 3700, Training MSE: 0.7279054522514343\n",
      "Epoch: 3800, Training MSE: 0.7220546007156372\n",
      "Epoch: 3900, Training MSE: 0.7185580730438232\n",
      "Epoch: 4000, Training MSE: 0.7203724980354309\n",
      "Epoch: 4100, Training MSE: 0.718570351600647\n",
      "Epoch: 4200, Training MSE: 0.7186288237571716\n",
      "Epoch: 4300, Training MSE: 0.718431293964386\n",
      "Epoch: 4400, Training MSE: 0.7194321751594543\n",
      "Epoch: 4500, Training MSE: 0.7187492251396179\n",
      "Epoch: 4600, Training MSE: 0.7183384895324707\n",
      "Epoch: 4700, Training MSE: 0.7189689874649048\n",
      "Epoch: 4800, Training MSE: 0.7243207693099976\n",
      "Epoch: 4900, Training MSE: 0.7182765007019043\n",
      "Epoch: 5000, Training MSE: 0.7182835936546326\n",
      "Epoch: 5100, Training MSE: 0.7182676792144775\n",
      "Epoch: 5200, Training MSE: 0.7185881733894348\n",
      "Epoch: 5300, Training MSE: 0.7186785936355591\n",
      "Epoch: 5400, Training MSE: 0.7200321555137634\n",
      "Epoch: 5500, Training MSE: 0.7186060547828674\n",
      "Epoch: 5600, Training MSE: 0.7181943655014038\n",
      "Epoch: 5700, Training MSE: 0.7183360457420349\n",
      "Epoch: 5800, Training MSE: 0.7188419699668884\n",
      "Epoch: 5900, Training MSE: 0.7205692529678345\n",
      "Epoch: 6000, Training MSE: 0.7182824015617371\n",
      "Epoch: 6100, Training MSE: 0.718090295791626\n",
      "Epoch: 6200, Training MSE: 0.7280497550964355\n",
      "Epoch: 6300, Training MSE: 0.7187412977218628\n",
      "Epoch: 6400, Training MSE: 0.7210018038749695\n",
      "Epoch: 6500, Training MSE: 0.7185873985290527\n",
      "Epoch: 6600, Training MSE: 0.7180370092391968\n",
      "Epoch: 6700, Training MSE: 0.7180405855178833\n",
      "Epoch: 6800, Training MSE: 0.7202214002609253\n",
      "Epoch: 6900, Training MSE: 0.7182007431983948\n",
      "Epoch: 7000, Training MSE: 0.7180948257446289\n",
      "Epoch: 7100, Training MSE: 0.7194232940673828\n",
      "Epoch: 7200, Training MSE: 0.7182087898254395\n",
      "Epoch: 7300, Training MSE: 0.7199987173080444\n",
      "Epoch: 7400, Training MSE: 0.7214100360870361\n",
      "Epoch: 7500, Training MSE: 0.7184656262397766\n",
      "Epoch: 7600, Training MSE: 0.7179364562034607\n",
      "Epoch: 7700, Training MSE: 0.7178946137428284\n",
      "Epoch: 7800, Training MSE: 0.7179751396179199\n",
      "Epoch: 7900, Training MSE: 0.7179630994796753\n",
      "Epoch: 8000, Training MSE: 0.717919111251831\n",
      "Epoch: 8100, Training MSE: 0.7184308767318726\n",
      "Epoch: 8200, Training MSE: 0.7193396091461182\n",
      "Epoch: 8300, Training MSE: 0.7180232405662537\n",
      "Epoch: 8400, Training MSE: 0.723710834980011\n",
      "Epoch: 8500, Training MSE: 0.7184150218963623\n",
      "Epoch: 8600, Training MSE: 0.7178873419761658\n",
      "Epoch: 8700, Training MSE: 0.7182113528251648\n",
      "Epoch: 8800, Training MSE: 0.7178804874420166\n",
      "Epoch: 8900, Training MSE: 0.7179666757583618\n",
      "Epoch: 9000, Training MSE: 0.7194857597351074\n",
      "Epoch: 9100, Training MSE: 0.7189986109733582\n",
      "Epoch: 9200, Training MSE: 0.71782386302948\n",
      "Epoch: 9300, Training MSE: 0.717971920967102\n",
      "Epoch: 9400, Training MSE: 0.718605101108551\n",
      "Epoch: 9500, Training MSE: 0.7181153297424316\n",
      "Epoch: 9600, Training MSE: 0.718316912651062\n",
      "Epoch: 9700, Training MSE: 0.7184526324272156\n",
      "Epoch: 9800, Training MSE: 0.7238094210624695\n",
      "Epoch: 9900, Training MSE: 0.7191541194915771\n",
      "Test MSE: 0.8675589561462402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecommenderSystem(\n",
       "  (conv1): GCNConv(10334, 128)\n",
       "  (conv2): GCNConv(128, 64)\n",
       "  (embed): Linear(in_features=64, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "model = RecommenderSystem().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-3)\n",
    "\n",
    "# Build adjusted edge index\n",
    "edge_index = torch.tensor(ratings_df[['userId', 'movieId']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# All the other parts are the same...\n",
    "\n",
    "# Split the edges into train and test\n",
    "edge_train, edge_test, edge_attr_train, edge_attr_test = train_test_split(\n",
    "    edge_index.T, edge_attr, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test Data objects\n",
    "data_train = Data(x=x, edge_index=edge_train.T, edge_attr=edge_attr_train)\n",
    "data_test = Data(x=x, edge_index=edge_test.T, edge_attr=edge_attr_test)\n",
    "\n",
    "# Move data to device\n",
    "data_train = data_train.to(device)\n",
    "data_test = data_test.to(device)\n",
    "\n",
    "# For the model, adjust embedding fetching \n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(data_train)\n",
    "    user_embeddings = embeddings[data_train.edge_index[0]]\n",
    "    movie_embeddings = embeddings[data_train.edge_index[1]]\n",
    "    predictions = (user_embeddings * movie_embeddings).sum(dim=1)\n",
    "    loss = torch.nn.functional.mse_loss(predictions, data_train.edge_attr.squeeze(1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print training loss every 20 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Training MSE: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(data_test)\n",
    "    user_embeddings = embeddings[data_test.edge_index[0]]\n",
    "    movie_embeddings = embeddings[data_test.edge_index[1]]\n",
    "    predictions = (user_embeddings * movie_embeddings).sum(dim=1)\n",
    "    loss = torch.nn.functional.mse_loss(predictions, data_test.edge_attr.squeeze(1))\n",
    "    print(f\"Test MSE: {loss.item()}\")\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7c4b75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 0: [694, 686, 862, 602, 277]\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(user_id, top_n=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data)\n",
    "        \n",
    "        # Compute scores for each movie for the given user\n",
    "        user_embedding = embeddings[user_id]\n",
    "        movie_embeddings = embeddings[user_num:]  # only consider movie nodes\n",
    "        scores = (user_embedding * movie_embeddings).sum(dim=1)\n",
    "        \n",
    "        # Exclude movies the user has already rated\n",
    "        rated_movies = data.edge_index[1][data.edge_index[0] == user_id]\n",
    "        scores[rated_movies] = -float('inf')\n",
    "\n",
    "        # Get the indices of the top N scores\n",
    "        top_movie_ids = scores.topk(top_n).indices\n",
    "\n",
    "        print(f\"Top {top_n} recommendations for user {user_id}: {top_movie_ids.tolist()}\")\n",
    "\n",
    "# Get recommendations for user 0\n",
    "get_recommendations(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
