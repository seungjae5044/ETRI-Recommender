2023-10-10 16:30:28,644 - root - INFO - Namespace(seed=0, data_name='culture', data_dir='datasets/', use_pretrain=0, pretrain_embedding_dir='datasets/pretrain/', pretrain_model_path='trained_model/culture/model_last.pth', cf_batch_size=1024, kg_batch_size=2048, test_batch_size=10000, embed_dim=64, relation_dim=64, laplacian_type='random-walk', aggregation_type='bi-interaction', conv_dim_list='[64, 32, 16]', mess_dropout='[0.1, 0.1, 0.1]', kg_l2loss_lambda=1e-05, cf_l2loss_lambda=1e-05, lr=0.001, n_epoch=300, stopping_steps=30, cf_print_every=1, kg_print_every=1, evaluate_every=10, Ks='[20, 40, 60, 80, 100]', save_dir='trained_model/culture')
2023-10-10 16:30:29,059 - root - INFO - n_users:           1835
2023-10-10 16:30:29,060 - root - INFO - n_items:           410
2023-10-10 16:30:29,061 - root - INFO - n_entities:        410
2023-10-10 16:30:29,061 - root - INFO - n_users_entities:  2245
2023-10-10 16:30:29,062 - root - INFO - n_relations:       24
2023-10-10 16:30:29,063 - root - INFO - n_h_list:          15046
2023-10-10 16:30:29,063 - root - INFO - n_t_list:          15046
2023-10-10 16:30:29,064 - root - INFO - n_r_list:          15046
2023-10-10 16:30:29,064 - root - INFO - n_cf_train:        5484
2023-10-10 16:30:29,065 - root - INFO - n_cf_test:         3661
2023-10-10 16:30:29,065 - root - INFO - n_kg_train:        15046
2023-10-10 16:30:30,001 - root - INFO - KGAT(
  (entity_user_embed): Embedding(2245, 64)
  (relation_embed): Embedding(24, 64)
  (aggregator_layers): ModuleList(
    (0): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
      (linear1): Linear(in_features=64, out_features=64, bias=True)
      (linear2): Linear(in_features=64, out_features=64, bias=True)
    )
    (1): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
      (linear1): Linear(in_features=64, out_features=32, bias=True)
      (linear2): Linear(in_features=64, out_features=32, bias=True)
    )
    (2): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
      (linear1): Linear(in_features=32, out_features=16, bias=True)
      (linear2): Linear(in_features=32, out_features=16, bias=True)
    )
  )
)
2023-10-10 16:30:30,898 - root - INFO - CF Training: Epoch 0001 Iter 0001 / 0006 | Time 0.9s | Iter Loss 0.7186 | Iter Mean Loss 0.7186
2023-10-10 16:30:30,932 - root - INFO - CF Training: Epoch 0001 Iter 0002 / 0006 | Time 0.0s | Iter Loss 0.7109 | Iter Mean Loss 0.7148
2023-10-10 16:30:30,965 - root - INFO - CF Training: Epoch 0001 Iter 0003 / 0006 | Time 0.0s | Iter Loss 0.6982 | Iter Mean Loss 0.7092
2023-10-10 16:30:31,012 - root - INFO - CF Training: Epoch 0001 Iter 0004 / 0006 | Time 0.0s | Iter Loss 0.6825 | Iter Mean Loss 0.7026
2023-10-10 16:30:31,045 - root - INFO - CF Training: Epoch 0001 Iter 0005 / 0006 | Time 0.0s | Iter Loss 0.6715 | Iter Mean Loss 0.6963
2023-10-10 16:30:31,079 - root - INFO - CF Training: Epoch 0001 Iter 0006 / 0006 | Time 0.0s | Iter Loss 0.6569 | Iter Mean Loss 0.6898
2023-10-10 16:30:31,080 - root - INFO - CF Training: Epoch 0001 Total Iter 0006 | Total Time 1.1s | Iter Mean Loss 0.6898
2023-10-10 16:30:31,121 - root - INFO - KG Training: Epoch 0001 Iter 0001 / 0008 | Time 0.0s | Iter Loss 0.6925 | Iter Mean Loss 0.6925
2023-10-10 16:30:31,157 - root - INFO - KG Training: Epoch 0001 Iter 0002 / 0008 | Time 0.0s | Iter Loss 0.6900 | Iter Mean Loss 0.6913
2023-10-10 16:30:31,192 - root - INFO - KG Training: Epoch 0001 Iter 0003 / 0008 | Time 0.0s | Iter Loss 0.6874 | Iter Mean Loss 0.6900
2023-10-10 16:30:31,243 - root - INFO - KG Training: Epoch 0001 Iter 0004 / 0008 | Time 0.1s | Iter Loss 0.6845 | Iter Mean Loss 0.6886
2023-10-10 16:30:31,278 - root - INFO - KG Training: Epoch 0001 Iter 0005 / 0008 | Time 0.0s | Iter Loss 0.6802 | Iter Mean Loss 0.6869
2023-10-10 16:30:31,313 - root - INFO - KG Training: Epoch 0001 Iter 0006 / 0008 | Time 0.0s | Iter Loss 0.6754 | Iter Mean Loss 0.6850
2023-10-10 16:30:31,347 - root - INFO - KG Training: Epoch 0001 Iter 0007 / 0008 | Time 0.0s | Iter Loss 0.6699 | Iter Mean Loss 0.6829
2023-10-10 16:30:31,382 - root - INFO - KG Training: Epoch 0001 Iter 0008 / 0008 | Time 0.0s | Iter Loss 0.6623 | Iter Mean Loss 0.6803
2023-10-10 16:30:31,383 - root - INFO - KG Training: Epoch 0001 Total Iter 0008 | Total Time 0.3s | Iter Mean Loss 0.6803
2023-10-10 16:30:31,390 - root - INFO - Update Attention: Epoch 0001 | Total Time 0.0s
2023-10-10 16:30:31,391 - root - INFO - CF + KG Training: Epoch 0001 | Total Time 1.4s
2023-10-10 16:30:31,441 - root - INFO - CF Training: Epoch 0002 Iter 0001 / 0006 | Time 0.0s | Iter Loss 0.6387 | Iter Mean Loss 0.6387
2023-10-10 16:30:31,485 - root - INFO - CF Training: Epoch 0002 Iter 0002 / 0006 | Time 0.0s | Iter Loss 0.6431 | Iter Mean Loss 0.6409
2023-10-10 16:30:31,532 - root - INFO - CF Training: Epoch 0002 Iter 0003 / 0006 | Time 0.0s | Iter Loss 0.6340 | Iter Mean Loss 0.6386
2023-10-10 16:30:31,577 - root - INFO - CF Training: Epoch 0002 Iter 0004 / 0006 | Time 0.0s | Iter Loss 0.6303 | Iter Mean Loss 0.6365
2023-10-10 16:30:31,623 - root - INFO - CF Training: Epoch 0002 Iter 0005 / 0006 | Time 0.0s | Iter Loss 0.6253 | Iter Mean Loss 0.6343
2023-10-10 16:30:31,659 - root - INFO - CF Training: Epoch 0002 Iter 0006 / 0006 | Time 0.0s | Iter Loss 0.6026 | Iter Mean Loss 0.6290
2023-10-10 16:30:31,660 - root - INFO - CF Training: Epoch 0002 Total Iter 0006 | Total Time 0.3s | Iter Mean Loss 0.6290
2023-10-10 16:30:31,716 - root - INFO - KG Training: Epoch 0002 Iter 0001 / 0008 | Time 0.1s | Iter Loss 0.6544 | Iter Mean Loss 0.6544
2023-10-10 16:30:31,770 - root - INFO - KG Training: Epoch 0002 Iter 0002 / 0008 | Time 0.1s | Iter Loss 0.6451 | Iter Mean Loss 0.6498
2023-10-10 16:30:31,823 - root - INFO - KG Training: Epoch 0002 Iter 0003 / 0008 | Time 0.1s | Iter Loss 0.6346 | Iter Mean Loss 0.6447
2023-10-10 16:30:31,858 - root - INFO - KG Training: Epoch 0002 Iter 0004 / 0008 | Time 0.0s | Iter Loss 0.6246 | Iter Mean Loss 0.6397
2023-10-10 16:30:31,893 - root - INFO - KG Training: Epoch 0002 Iter 0005 / 0008 | Time 0.0s | Iter Loss 0.6097 | Iter Mean Loss 0.6337
2023-10-10 16:30:31,928 - root - INFO - KG Training: Epoch 0002 Iter 0006 / 0008 | Time 0.0s | Iter Loss 0.5996 | Iter Mean Loss 0.6280
2023-10-10 16:30:31,975 - root - INFO - KG Training: Epoch 0002 Iter 0007 / 0008 | Time 0.0s | Iter Loss 0.5842 | Iter Mean Loss 0.6217
2023-10-10 16:30:32,018 - root - INFO - KG Training: Epoch 0002 Iter 0008 / 0008 | Time 0.0s | Iter Loss 0.5702 | Iter Mean Loss 0.6153
2023-10-10 16:30:32,018 - root - INFO - KG Training: Epoch 0002 Total Iter 0008 | Total Time 0.4s | Iter Mean Loss 0.6153
2023-10-10 16:30:32,035 - root - INFO - Update Attention: Epoch 0002 | Total Time 0.0s
2023-10-10 16:30:32,036 - root - INFO - CF + KG Training: Epoch 0002 | Total Time 0.6s
2023-10-10 16:30:32,071 - root - INFO - CF Training: Epoch 0003 Iter 0001 / 0006 | Time 0.0s | Iter Loss 0.5915 | Iter Mean Loss 0.5915
2023-10-10 16:30:32,106 - root - INFO - CF Training: Epoch 0003 Iter 0002 / 0006 | Time 0.0s | Iter Loss 0.5694 | Iter Mean Loss 0.5804
