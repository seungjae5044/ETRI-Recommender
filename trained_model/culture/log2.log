2023-10-10 16:22:16,567 - root - INFO - Namespace(seed=0, data_name='culture', data_dir='datasets/', use_pretrain=0, pretrain_embedding_dir='datasets/pretrain/', pretrain_model_path='trained_model/culture/model_last.pth', cf_batch_size=1024, kg_batch_size=2048, test_batch_size=10000, embed_dim=64, relation_dim=64, laplacian_type='random-walk', aggregation_type='bi-interaction', conv_dim_list='[64, 32, 16]', mess_dropout='[0.1, 0.1, 0.1]', kg_l2loss_lambda=1e-05, cf_l2loss_lambda=1e-05, lr=0.001, n_epoch=1, stopping_steps=30, cf_print_every=1, kg_print_every=1, evaluate_every=10, Ks='[20, 40, 60, 80, 100]', save_dir='trained_model/culture')
2023-10-10 16:22:16,994 - root - INFO - n_users:           1835
2023-10-10 16:22:16,995 - root - INFO - n_items:           410
2023-10-10 16:22:16,995 - root - INFO - n_entities:        410
2023-10-10 16:22:16,996 - root - INFO - n_users_entities:  2245
2023-10-10 16:22:16,996 - root - INFO - n_relations:       24
2023-10-10 16:22:16,997 - root - INFO - n_h_list:          15046
2023-10-10 16:22:16,997 - root - INFO - n_t_list:          15046
2023-10-10 16:22:16,998 - root - INFO - n_r_list:          15046
2023-10-10 16:22:16,998 - root - INFO - n_cf_train:        5484
2023-10-10 16:22:17,000 - root - INFO - n_cf_test:         3661
2023-10-10 16:22:17,001 - root - INFO - n_kg_train:        15046
2023-10-10 16:22:17,898 - root - INFO - KGAT(
  (entity_user_embed): Embedding(2245, 64)
  (relation_embed): Embedding(24, 64)
  (aggregator_layers): ModuleList(
    (0): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
      (linear1): Linear(in_features=64, out_features=64, bias=True)
      (linear2): Linear(in_features=64, out_features=64, bias=True)
    )
    (1): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
      (linear1): Linear(in_features=64, out_features=32, bias=True)
      (linear2): Linear(in_features=64, out_features=32, bias=True)
    )
    (2): Aggregator(
      (message_dropout): Dropout(p=0.1, inplace=False)
      (activation): LeakyReLU(negative_slope=0.01)
      (linear1): Linear(in_features=32, out_features=16, bias=True)
      (linear2): Linear(in_features=32, out_features=16, bias=True)
    )
  )
)
2023-10-10 16:22:18,760 - root - INFO - CF Training: Epoch 0001 Iter 0001 / 0006 | Time 0.9s | Iter Loss 0.7186 | Iter Mean Loss 0.7186
2023-10-10 16:22:18,804 - root - INFO - CF Training: Epoch 0001 Iter 0002 / 0006 | Time 0.0s | Iter Loss 0.7109 | Iter Mean Loss 0.7148
2023-10-10 16:22:18,834 - root - INFO - CF Training: Epoch 0001 Iter 0003 / 0006 | Time 0.0s | Iter Loss 0.6982 | Iter Mean Loss 0.7092
2023-10-10 16:22:18,866 - root - INFO - CF Training: Epoch 0001 Iter 0004 / 0006 | Time 0.0s | Iter Loss 0.6825 | Iter Mean Loss 0.7026
2023-10-10 16:22:18,898 - root - INFO - CF Training: Epoch 0001 Iter 0005 / 0006 | Time 0.0s | Iter Loss 0.6715 | Iter Mean Loss 0.6963
2023-10-10 16:22:18,930 - root - INFO - CF Training: Epoch 0001 Iter 0006 / 0006 | Time 0.0s | Iter Loss 0.6569 | Iter Mean Loss 0.6898
2023-10-10 16:22:18,930 - root - INFO - CF Training: Epoch 0001 Total Iter 0006 | Total Time 1.0s | Iter Mean Loss 0.6898
2023-10-10 16:22:18,964 - root - INFO - KG Training: Epoch 0001 Iter 0001 / 0008 | Time 0.0s | Iter Loss 0.6925 | Iter Mean Loss 0.6925
2023-10-10 16:22:19,021 - root - INFO - KG Training: Epoch 0001 Iter 0002 / 0008 | Time 0.1s | Iter Loss 0.6900 | Iter Mean Loss 0.6913
2023-10-10 16:22:19,074 - root - INFO - KG Training: Epoch 0001 Iter 0003 / 0008 | Time 0.1s | Iter Loss 0.6874 | Iter Mean Loss 0.6900
2023-10-10 16:22:19,108 - root - INFO - KG Training: Epoch 0001 Iter 0004 / 0008 | Time 0.0s | Iter Loss 0.6845 | Iter Mean Loss 0.6886
2023-10-10 16:22:19,154 - root - INFO - KG Training: Epoch 0001 Iter 0005 / 0008 | Time 0.0s | Iter Loss 0.6802 | Iter Mean Loss 0.6869
2023-10-10 16:22:19,189 - root - INFO - KG Training: Epoch 0001 Iter 0006 / 0008 | Time 0.0s | Iter Loss 0.6754 | Iter Mean Loss 0.6850
2023-10-10 16:22:19,237 - root - INFO - KG Training: Epoch 0001 Iter 0007 / 0008 | Time 0.0s | Iter Loss 0.6699 | Iter Mean Loss 0.6829
2023-10-10 16:22:19,272 - root - INFO - KG Training: Epoch 0001 Iter 0008 / 0008 | Time 0.0s | Iter Loss 0.6623 | Iter Mean Loss 0.6803
2023-10-10 16:22:19,272 - root - INFO - KG Training: Epoch 0001 Total Iter 0008 | Total Time 0.3s | Iter Mean Loss 0.6803
2023-10-10 16:22:19,280 - root - INFO - Update Attention: Epoch 0001 | Total Time 0.0s
2023-10-10 16:22:19,281 - root - INFO - CF + KG Training: Epoch 0001 | Total Time 1.4s
2023-10-10 16:22:19,432 - root - INFO - CF Evaluation: Epoch 0001 | Total Time 0.2s | Precision [0.0109, 0.0094], Recall [0.1095, 0.4738], NDCG [0.0484, 0.1269]
2023-10-10 16:22:19,438 - root - INFO - Save model on epoch 0001!
2023-10-10 16:22:19,441 - root - INFO - Best CF Evaluation: Epoch 0001 | Precision [0.0109, 0.0094], Recall [0.1095, 0.4738], NDCG [0.0484, 0.1269]
2023-10-10 16:22:19,745 - root - INFO - n_users:           1835
2023-10-10 16:22:19,745 - root - INFO - n_items:           410
2023-10-10 16:22:19,746 - root - INFO - n_entities:        410
2023-10-10 16:22:19,746 - root - INFO - n_users_entities:  2245
2023-10-10 16:22:19,747 - root - INFO - n_relations:       24
2023-10-10 16:22:19,747 - root - INFO - n_h_list:          15046
2023-10-10 16:22:19,748 - root - INFO - n_t_list:          15046
2023-10-10 16:22:19,748 - root - INFO - n_r_list:          15046
2023-10-10 16:22:19,749 - root - INFO - n_cf_train:        5484
2023-10-10 16:22:19,749 - root - INFO - n_cf_test:         3661
2023-10-10 16:22:19,749 - root - INFO - n_kg_train:        15046
